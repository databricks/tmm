{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./CityLocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58b12e3c-d938-4d24-a1c4-98e1864a955c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "package com.databricks.dais2025\n",
    "\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "/**\n",
    " * Generate synthetic environmental sensor data using Spark rate source\n",
    " * \n",
    " * This is a Scala equivalent of the Python example6_rate_source.py\n",
    " */\n",
    "object SensorDataGenerator {\n",
    "\n",
    "  val sensorSchema = StructType(Seq(\n",
    "    StructField(\"sensor_id\", StringType, nullable = true),\n",
    "    StructField(\"city\", StringType, nullable = true),\n",
    "    StructField(\"location\", StringType, nullable = true),\n",
    "    StructField(\"timestamp\", TimestampType, nullable = true),\n",
    "    StructField(\"temperature\", DoubleType, nullable = false),\n",
    "    StructField(\"humidity\", DoubleType, nullable = false),\n",
    "    StructField(\"co2_level\", DoubleType, nullable = false),\n",
    "    StructField(\"pm25_level\", DoubleType, nullable = false)\n",
    "  ))\n",
    "\n",
    "  /**\n",
    "   * Generate environmental sensor data with city information using Spark rate source\n",
    "   * \n",
    "   * @param spark SparkSession object\n",
    "   * @param rowsPerSecond Rate of data generation (default: 10)\n",
    "   * @param numPartitions Number of partitions for the rate source (default: 4)\n",
    "   * @return Streaming DataFrame with environmental sensor data\n",
    "   */\n",
    "  def createStream(\n",
    "      spark: SparkSession,\n",
    "      rowsPerSecond: Int = 10,\n",
    "      numPartitions: Int = 4,\n",
    "      partitionBySensorId: Boolean = false\n",
    "  ): DataFrame = {\n",
    "\n",
    "    // Reference city locations from external object (see CityLocations.ipynb)\n",
    "    val cityLocations = CityLocations.cityLocations\n",
    "    val cities = cityLocations.keys.toSeq\n",
    "\n",
    "    // Start with rate source\n",
    "    var df = spark\n",
    "      .readStream\n",
    "      .format(\"rate\")\n",
    "      .option(\"rowsPerSecond\", rowsPerSecond)\n",
    "      .option(\"numPartitions\", numPartitions)\n",
    "      .load()\n",
    "\n",
    "    // Rename value to generator_id to match dbldatagen\n",
    "    df = df.withColumnRenamed(\"value\", \"generator_id\")\n",
    "\n",
    "    // Add city_for_id column (cycling through cities based on generator_id)\n",
    "    df = df.withColumn(\n",
    "      \"city_for_id\",\n",
    "      element_at(\n",
    "        array(cities.map(lit): _*),\n",
    "        (col(\"generator_id\") % lit(cities.length)).cast(IntegerType) + 1\n",
    "      )\n",
    "    )\n",
    "\n",
    "    // Add sensor_id\n",
    "    df = df.withColumn(\n",
    "      \"sensor_id\",\n",
    "      concat(\n",
    "        substring(col(\"city_for_id\"), 1, 3),\n",
    "        lit(\"-SENSOR-\"),\n",
    "        col(\"generator_id\").cast(StringType)\n",
    "      )\n",
    "    )\n",
    "\n",
    "    // Add city column\n",
    "    df = df.withColumn(\"city\", col(\"city_for_id\"))\n",
    "\n",
    "    // Add location column with case statement for each city\n",
    "    var locationExpr: org.apache.spark.sql.Column = null\n",
    "\n",
    "    for ((city, locations) <- cityLocations) {\n",
    "      val cityArray = array(locations.map(lit): _*)\n",
    "      val cityCondition = when(\n",
    "        col(\"city\") === lit(city),\n",
    "        element_at(cityArray, (floor(rand() * locations.length)).cast(IntegerType) + 1)\n",
    "      )\n",
    "\n",
    "      if (locationExpr == null) {\n",
    "        locationExpr = cityCondition\n",
    "      } else {\n",
    "        locationExpr = locationExpr.when(\n",
    "          col(\"city\") === lit(city),\n",
    "          element_at(cityArray, (floor(rand() * locations.length)).cast(IntegerType) + 1)\n",
    "        )\n",
    "      }\n",
    "    }\n",
    "\n",
    "    df = df.withColumn(\"location\", locationExpr)\n",
    "\n",
    "    // Use the streaming timestamp from rate source\n",
    "    df = df.withColumnRenamed(\"timestamp\", \"reading_timestamp\")\n",
    "\n",
    "    // Add temperature with multiplier (to create anomalies)\n",
    "    df = df.withColumn(\n",
    "      \"temp_multiplier\",\n",
    "      when(rand() < 0.2, lit(3.0))\n",
    "        .when(rand() < 0.4, lit(0.2))\n",
    "        .otherwise(lit(1.0))\n",
    "    )\n",
    "\n",
    "    // Base temperature by city\n",
    "    df = df.withColumn(\n",
    "      \"base_temp\",\n",
    "      when(col(\"city\") === \"Tokyo\", lit(25) + rand() * 5)\n",
    "        .when(col(\"city\") === \"Sydney\", lit(22) + rand() * 5)\n",
    "        .when(col(\"city\") === \"New York\", lit(20) + rand() * 5)\n",
    "        .when(col(\"city\") === \"London\", lit(18) + rand() * 5)\n",
    "        .when(col(\"city\") === \"Paris\", lit(21) + rand() * 5)\n",
    "        .otherwise(lit(20) + rand() * 5)\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\"temperature\", col(\"base_temp\") * col(\"temp_multiplier\"))\n",
    "\n",
    "    // Humidity with multiplier\n",
    "    df = df.withColumn(\n",
    "      \"humidity_multiplier\",\n",
    "      when(rand() < 0.25, lit(1.8)).otherwise(lit(1.0))\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "      \"humidity\",\n",
    "      least(lit(100), (rand() * 60 + 30) * col(\"humidity_multiplier\"))\n",
    "    )\n",
    "\n",
    "    // CO2 level with multiplier\n",
    "    df = df.withColumn(\n",
    "      \"co2_multiplier\",\n",
    "      when(rand() < 0.3, lit(2.5)).otherwise(lit(1.0))\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "      \"co2_level\",\n",
    "      lit(350) + rand() * 800 * col(\"co2_multiplier\")\n",
    "    )\n",
    "\n",
    "    // PM2.5 level with multiplier\n",
    "    df = df.withColumn(\n",
    "      \"pm25_multiplier\",\n",
    "      when(rand() < 0.25, lit(3.0)).otherwise(lit(1.0))\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "      \"pm25_level\",\n",
    "      rand() * 30 * col(\"pm25_multiplier\")\n",
    "    )\n",
    "\n",
    "    // Drop intermediate columns\n",
    "    df = df.drop(\n",
    "      \"base_temp\", \"temp_multiplier\", \"humidity_multiplier\",\n",
    "      \"co2_multiplier\", \"pm25_multiplier\", \"city_for_id\"\n",
    "    )\n",
    "\n",
    "    df.selectExpr(\n",
    "      \"sensor_id\",\n",
    "      \"city\",\n",
    "      \"location\",\n",
    "      \"reading_timestamp as timestamp\",\n",
    "      \"temperature\",\n",
    "      \"humidity\",\n",
    "      \"co2_level\",\n",
    "      \"pm25_level\"\n",
    "    )\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "scala",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "SensorDataGenerator",
   "widgets": {}
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
